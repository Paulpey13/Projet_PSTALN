{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_transformer_POS_conv import *\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())  # Renvoie True si un GPU est disponible\n",
    "\n",
    "batch_size=16\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using the load_data_1 function\n",
    "sentences, pos_tags = load_data_1(\"UD_French-Sequoia/fr_sequoia-ud-train.conllu\")\n",
    "\n",
    "# Create character and tag mappings\n",
    "char_counts = Counter(char for sentence in sentences for word in sentence for char in word)\n",
    "char_to_ix = {char: i for i, char in enumerate(char_counts, start=2)}\n",
    "char_to_ix['<PAD>'], char_to_ix['<UNK>'] = 0, 1  # Padding and unknown character\n",
    "\n",
    "tag_counts = Counter(tag for tags in pos_tags for tag in tags)\n",
    "tag_to_ix = {tag: i for i, tag in enumerate(tag_counts)}\n",
    "\n",
    "max_word_len = max(len(word) for sentence in sentences for word in sentence)\n",
    "\n",
    "# Now load the data in the desired format using the load_data function\n",
    "train_sentences, train_pos_tags = load_data(\"UD_French-Sequoia/fr_sequoia-ud-train.conllu\", char_to_ix, max_word_len)\n",
    "validation_sentences, validation_pos_tags = load_data(\"UD_French-Sequoia/fr_sequoia-ud-dev.conllu\", char_to_ix, max_word_len)\n",
    "\n",
    "# Rest of your code for Dataset, DataLoader, Model initialization, etc.\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset = POSDataset(train_sentences, train_pos_tags, tag_to_ix, max_word_len,char_to_ix)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "validation_dataset = POSDataset(validation_sentences, validation_pos_tags, tag_to_ix, max_word_len,char_to_ix)\n",
    "validation_data_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "test_sentences, test_pos_tags = load_data(\"UD_French-Sequoia/fr_sequoia-ud-test.conllu\", char_to_ix, max_word_len)\n",
    "\n",
    "\n",
    "test_dataset = POSDataset(test_sentences, test_pos_tags, tag_to_ix, max_word_len,char_to_ix)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model initialization\n",
    "num_chars = len(char_to_ix)\n",
    "char_embedding_dim = 512\n",
    "num_filters = 256\n",
    "kernel_size = 3\n",
    "nhead = 4\n",
    "nhid = 512\n",
    "nlayers = 3\n",
    "tagset_size = len(tag_to_ix)\n",
    "\n",
    "char_embedding_dim_tab = [512, 256, 128]\n",
    "num_filters_tab = [256, 128]\n",
    "kernel_size_tab = [2,3,4]\n",
    "nhead_tab = [4]\n",
    "nhid_tab = [512, 256, 128]\n",
    "nlayers_tab = [1,2,3, 4, 5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 0.9867, Validation Accuracy: 0.6801\n",
      "best model accuracy: 0.6801\n",
      "Epoch 1, Loss: 1.5117519634110588\n",
      "Epoch 2, Validation Loss: 0.7947, Validation Accuracy: 0.7355\n",
      "best model accuracy: 0.7355\n",
      "Epoch 2, Loss: 0.9995766976049968\n",
      "Epoch 3, Validation Loss: 0.7221, Validation Accuracy: 0.7535\n",
      "best model accuracy: 0.7535\n",
      "Epoch 3, Loss: 0.8602390847035817\n",
      "Epoch 4, Validation Loss: 0.6617, Validation Accuracy: 0.7720\n",
      "best model accuracy: 0.7720\n",
      "Epoch 4, Loss: 0.7863857235227313\n",
      "Epoch 5, Validation Loss: 0.6227, Validation Accuracy: 0.7866\n",
      "best model accuracy: 0.7866\n",
      "Epoch 5, Loss: 0.7353454798460006\n",
      "Epoch 6, Validation Loss: 0.5863, Validation Accuracy: 0.8011\n",
      "best model accuracy: 0.8011\n",
      "Epoch 6, Loss: 0.6944177363600049\n",
      "Epoch 7, Validation Loss: 0.5606, Validation Accuracy: 0.8113\n",
      "best model accuracy: 0.8113\n",
      "Epoch 7, Loss: 0.6654419977750097\n",
      "Epoch 8, Validation Loss: 0.5409, Validation Accuracy: 0.8192\n",
      "best model accuracy: 0.8192\n",
      "Epoch 8, Loss: 0.6358740908758981\n",
      "Epoch 9, Validation Loss: 0.5202, Validation Accuracy: 0.8256\n",
      "best model accuracy: 0.8256\n",
      "Epoch 9, Loss: 0.6172786410365786\n",
      "Epoch 10, Validation Loss: 0.5036, Validation Accuracy: 0.8325\n",
      "best model accuracy: 0.8325\n",
      "Epoch 10, Loss: 0.5987016850284168\n",
      "Epoch 11, Validation Loss: 0.4874, Validation Accuracy: 0.8408\n",
      "best model accuracy: 0.8408\n",
      "Epoch 11, Loss: 0.58331736688103\n",
      "Epoch 12, Validation Loss: 0.4737, Validation Accuracy: 0.8447\n",
      "best model accuracy: 0.8447\n",
      "Epoch 12, Loss: 0.5668771415948868\n",
      "Epoch 13, Validation Loss: 0.4642, Validation Accuracy: 0.8461\n",
      "best model accuracy: 0.8461\n",
      "Epoch 13, Loss: 0.546894514134952\n",
      "Epoch 14, Validation Loss: 0.4541, Validation Accuracy: 0.8508\n",
      "best model accuracy: 0.8508\n",
      "Epoch 14, Loss: 0.536340834413256\n",
      "Epoch 15, Validation Loss: 0.4459, Validation Accuracy: 0.8514\n",
      "best model accuracy: 0.8514\n",
      "Epoch 15, Loss: 0.5237325136150632\n",
      "Epoch 16, Validation Loss: 0.4440, Validation Accuracy: 0.8529\n",
      "best model accuracy: 0.8529\n",
      "Epoch 16, Loss: 0.5155452909214157\n",
      "Epoch 17, Validation Loss: 0.4263, Validation Accuracy: 0.8583\n",
      "best model accuracy: 0.8583\n",
      "Epoch 17, Loss: 0.5016126730612346\n",
      "Epoch 18, Validation Loss: 0.4259, Validation Accuracy: 0.8603\n",
      "best model accuracy: 0.8603\n",
      "Epoch 18, Loss: 0.49446285750184743\n",
      "Epoch 19, Validation Loss: 0.4202, Validation Accuracy: 0.8643\n",
      "best model accuracy: 0.8643\n",
      "Epoch 19, Loss: 0.4863074490002223\n",
      "Epoch 20, Validation Loss: 0.4063, Validation Accuracy: 0.8685\n",
      "best model accuracy: 0.8685\n",
      "Epoch 20, Loss: 0.47879101442439215\n",
      "Epoch 21, Validation Loss: 0.4067, Validation Accuracy: 0.8651\n",
      "Epoch 21, Loss: 0.4697392091155052\n",
      "Epoch 22, Validation Loss: 0.3956, Validation Accuracy: 0.8741\n",
      "best model accuracy: 0.8741\n",
      "Epoch 22, Loss: 0.4635518912758146\n",
      "Epoch 23, Validation Loss: 0.3876, Validation Accuracy: 0.8772\n",
      "best model accuracy: 0.8772\n",
      "Epoch 23, Loss: 0.45790702125855853\n",
      "Epoch 24, Validation Loss: 0.3864, Validation Accuracy: 0.8786\n",
      "best model accuracy: 0.8786\n",
      "Epoch 24, Loss: 0.4502271871481623\n",
      "Epoch 25, Validation Loss: 0.3788, Validation Accuracy: 0.8833\n",
      "best model accuracy: 0.8833\n",
      "Epoch 25, Loss: 0.4451033611382757\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m tag_scores \u001b[38;5;241m=\u001b[39m model(sentence_in)\n\u001b[0;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(tag_scores\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(tag_to_ix)), targets\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     28\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "patience = 2\n",
    "epochs=50\n",
    "results = []\n",
    "for char_embedding_dim in char_embedding_dim_tab:\n",
    "    for num_filters in num_filters_tab:\n",
    "        for kernel_size in kernel_size_tab:\n",
    "            for nhead in nhead_tab:\n",
    "                for nhid in nhid_tab:\n",
    "                    for nlayers in nlayers_tab:\n",
    "                        start_time = time.time()\n",
    "                        best_val_accuracy = 0\n",
    "                        epochs_no_improve = 0\n",
    "                        model = POSTransformerModel(num_chars, char_embedding_dim, num_filters, kernel_size, nhead, nhid, nlayers, tagset_size)\n",
    "                        loss_function = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "                        optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "                        #Training\n",
    "                        for epoch in range(epochs): \n",
    "                            model.train()\n",
    "                            model.to(device)  # Déplacer le modèle sur le GPU si disponible\n",
    "                            total_loss = 0\n",
    "                            for sentence_in, targets in data_loader:\n",
    "                                sentence_in, targets = sentence_in.to(device), targets.to(device)  # Déplacer les données sur le périphérique\n",
    "                                optimizer.zero_grad()\n",
    "                                tag_scores = model(sentence_in)\n",
    "                                loss = loss_function(tag_scores.view(-1, len(tag_to_ix)), targets.view(-1))\n",
    "                                loss.backward()\n",
    "                                optimizer.step()\n",
    "                                total_loss += loss.item()\n",
    "\n",
    "                            # Utiliser la fonction modifiée pour évaluer la validation loss et l'accuracy\n",
    "                            val_loss, val_accuracy = evaluate_model(model, validation_data_loader, loss_function,device, tag_to_ix)\n",
    "                            print(f\"Epoch {epoch+1}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "                            if val_accuracy > best_val_accuracy:\n",
    "                                best_val_accuracy = val_accuracy\n",
    "                                best_model = copy.deepcopy(model)\n",
    "                                print(f\"best model accuracy: {best_val_accuracy:.4f}\")\n",
    "                                epochs_no_improve = 0\n",
    "                            else:\n",
    "                                epochs_no_improve += 1\n",
    "\n",
    "                            # Arrêt précoce si aucune amélioration\n",
    "                            if epochs_no_improve == patience:\n",
    "                                print(\"Arrêt précoce : La loss de validation ne s'améliore plus\")\n",
    "                                break\n",
    "                            print(f\"Epoch {epoch+1}, Loss: {total_loss / len(data_loader)}\")\n",
    "                        end_time = time.time()\n",
    "                        elapsed_time = end_time - start_time\n",
    "                        final_epoch = epoch + 1  # ou epoch si vous utilisez break dans la boucle\n",
    "                        loss, accuracy = evaluate_model(best_model, test_data_loader, loss_function, device, tag_to_ix)\n",
    "                        print(f\"Test Accuracy : {accuracy:.4f}\")\n",
    "\n",
    "                        # Stocker les résultats\n",
    "                        result = {\n",
    "                            'char_embedding_dim': char_embedding_dim,\n",
    "                            'num_filters': num_filters,\n",
    "                            'kernel_size': kernel_size,\n",
    "                            'nhead': nhead,\n",
    "                            'nhid': nhid,\n",
    "                            'nlayers': nlayers,\n",
    "                            'best_val_accuracy': best_val_accuracy,\n",
    "                            'final_epoch': final_epoch,\n",
    "                            'elapsed_time': elapsed_time,\n",
    "                            'test_accuracy': accuracy\n",
    "                        }\n",
    "                        results.append(result)\n",
    "                        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
