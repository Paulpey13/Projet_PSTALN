Choix à effectuer :

1.1 Tâches de prédiction de structures
    On va partir pour l'instant sur 
        POS
        Lemmatisation
        Traits morphologiques
    OPTIONS:
        Si on a pas le time on peut potentiellement en enlever un,
        Si on est en avance on peut rajouter un model ou rajouter dans le model les expressions idiomatique

1.2 Stratégies de combinaison des tâches
    Ce serait mieux de partir sur un modele joint, plus stylé
    Mais si cest galere on fera 3 modèles
    Pipeline ça a l'air bien aussi mais je connais pas du tout 

1.3 Architectures des classifieurs
    Transformer car c'est ce qui se fait et ça peut être bien de s'entrainer à l'utiliser
    Surtout pour le transfer learning comme on en a pas trop fait

    Sinon si on galere LSTM/GRU très facile à utiliser et efficace

1.4 Langue des données
    Pour l'instant en français car on a ces données
    Après on pourra test en anglais et meme avec plusieurs langues pour répondre aux questions ci dessous

     (a) Peut-on faire un système unique capable de prédire des structures linguistiques pour plusieurs langues ? 

     (b) Peut-on bénéficier de données d’autres langues (proches) pour améliorer le système d’une langue donnée ? 

     (c) Peut-on apprendre des embeddings qui marchent pour plusieurs langues ? 

     (d) Est-ce que certaines paires (tâche, langue) sont plus difficiles que d’autres ?

1.5 Encodage des entrées
    Embedding de pytorch sont très bien pour l'instant

    Mais on peut comparer avec ceux pré entrainé et voir les meilleurs, ça nous fera un truc 
    à dire en plus sur le rapport (surtout pour mot ambigu etc)

1.6 Encodage des sorties
    Pour POS pas besoin
    Pour les autres à voir au fur et à mesure qu'on implémente, ce qui sera le + efficace,
    c'est facile à changer je pense

2 Données
    Universal Dependencies pour l'instant car on fait pas idiomatique

3 Évaluation du système
    Utiliser les scripts donné



Journal de bord (pour mettre à la fin du rapport si besoin)

Creation d'une baseline LSTM pour POS(pour faire un truc different du TP) 0.72 acc 50 epochs
Creation d'une baseline transformer pour POS (+ efficace que LSTM) 0.93 acc 50 epochs
à faire prochainement : 
    Cross validation pour les 2 pour trouver les meilleurs parametres

baseline transformer POS + Lemme :
    pour 50 epochs :
        POS acc 0.9570 (donc ça a augmenter juste avec l'ajout de la prediction de Lemme) (à vérifier)
        Lemme acc 0.8984 (à faire un transformer seul pour voir si ça change)
        Total acc (POS+Lemme)/2 : 0.9277
        Total loss 1.11

baseline transformer POS + Lemme + morphologiques
    POS acc 0.9570 (légère baisse mais j'imagine du au hasard (a verifier))
    Lemme 0.8898 (légère baisse aussi, peut être pas du au hasard du coup)
    morphs 0.9911 trop haut je pense que y'a un soucis
